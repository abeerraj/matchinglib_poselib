# MATCHING- AND POSELIB

- [Introduction](#introduction)
- [Supported Keypoint and Descriptor Types](#support-features)
- [Supported Matching Algorithms](#support-matching)
- [Supported Correspondence Filtering Techniques](#support-filtering)
- [Supported Pose Estimation Algorithms](#support-pose)
- [Installation](#installation)
    - [Dependencies](#dependencies)
        - [Docker](#docker)
        - [System-wide Installation on Linux Systems](#system-dependencies)
    - [Using Stand-Alone Executables without Docker](#executable)
    - [Library](#library)
- [Quick Start: Using Provided Test Data](#quick-start)
    - [Sparse Feature Matching](#quick-matching)
    - [Pose Estimation](#quick-pose)
- [Stand-Alone Executable for Feature Matching](#executable-matching)
- [Stand-Alone Executable for Pose Estimation](#executable-pose)
- [Stand-Alone Executable for Reading Test Data Generated by SemiRealSequence](#executable-test)
- [Interfacing the Library](#interface-lib)
    - [Calculation of Sparse Feature Matches](#interface-matching)
    - [Calculation of Relative Poses](#interface-pose)
    - [Continuous High Accuracy Stereo Pose Estimation](#interface-stereo)
    - [ROS](#interface-ros)
- [Testing Results on Supported Keypoint, Descriptor, and Matching Algorithm Types](#tests-features)
- [Testing Results on Supported Pose Estimation Algorithms](#tests-pose)
- [Publication](#publication)

## Introduction <a name="introduction"></a>

This library includes various algorithms for calculating, filtering, refining, and matching of sparse image features.
Moreover, multiple algorithms for estimating relative poses like different random sample consensus algorithms, 5pt solvers, cost functions, linear pose refinement algorithms, bundle adjustment (BA) options, and stereo rectification algorithms are provided.
For continuously estimating high accurate relative stereo poses, the library includes a framework that estimates stereo poses and continuously refines them using multiple stereo images (e.g. from a streaming stereo rig) while detecting pose changes to achieve pose accuracies comparable to offline calibration methods.

For easy interfacing, we provide 3 possibilities to interface the library:
* Stand-alone executables with a command-line interface to read image and calibration data from disk
* A library that can be integrated into your own application
* A ROS interface for reading continuous image data providing a launch file and the possibility to dynamically reconfigure parameters during runtime

We further provide testing results on various keypoint-descriptor combinations, matching algorithms, and pose estimation algorithms.

##Supported Keypoint and Descriptor Types <a name="support-features"></a>

Currently, all keypoint and descriptor types within [OpenCV](https://docs.opencv.org/4.2.0/d5/d51/group__features2d__main.html) (including [contrib](https://docs.opencv.org/4.2.0/d7/d7a/group__xfeatures2d__experiment.html)) in addition to [BOLD](https://github.com/vbalnt/bold) and [RIFF](http://press.liacs.nl/publications/RIFF%20-%20Retina-inspired%20Invariant%20Fast%20Feature%20Descriptor.pdf) are supported.

Keypoint types:
* FAST
* MSER
* ORB
* BRISK
* KAZE
* AKAZE
* STAR
* MSD
* SIFT
* SURF

Descriptor types:
* BRISK
* ORB
* KAZE
* AKAZE
* FREAK
* DAISY
* LATCH
* BGM
* BGM_HARD
* BGM_BILINEAR
* LBGM
* BINBOOST_64
* BINBOOST_128
* BINBOOST_256
* VGG_120
* VGG_80
* VGG_64
* VGG_48
* SIFT
* SURF
* RIFF
* BOLD

To enable SIFT and SURF, OpenCV must be built with enabled non-free code (contrib) and option `-DUSE_NON_FREE_CODE=ON` must be provided to CMake when building this library.

## Supported Matching Algorithms <a name="support-matching"></a>

* CASHASH:	    Cascade Hashing matcher from the [NMSLIB](https://github.com/nmslib/nmslib)
* GMBSOF:	    [Guided Matching based on Statistical Optical Flow](https://link.springer.com/chapter/10.1007/978-3-319-46478-7_7)
* HIRCLUIDX:    Hirarchical Clustering Index Matching from the [FLANN library](https://github.com/mariusmuja/flann)
* HIRKMEANS:    Hierarchical k-means tree matcher from the [FLANN library](https://github.com/mariusmuja/flann)
* LINEAR:	    Linear matching algorithm (Brute force) from the [FLANN library](https://github.com/mariusmuja/flann)
* LSHIDX:	    LSH Index Matching algorithm from the [FLANN library](https://github.com/mariusmuja/flann)
* RANDKDTREE:	Randomized KD-trees matcher from the [FLANN library](https://github.com/mariusmuja/flann)
* SWGRAPH:	    Small World Graph (SW-graph) from the [NMSLIB](https://github.com/nmslib/nmslib)
* HNSW:         Hiarchical Navigable Small World Graph from the [NMSLIB](https://github.com/nmslib/nmslib)
* VPTREE:       VP-tree or ball-tree from the [NMSLIB](https://github.com/nmslib/nmslib)
* MVPTREE:      Multi-Vantage Point Tree from the [NMSLIB](https://github.com/nmslib/nmslib)
* GHTREE:       GH-Tree from the [NMSLIB](https://github.com/nmslib/nmslib)
* LISTCLU:      List of clusters from the [NMSLIB](https://github.com/nmslib/nmslib)
* SATREE:       Spatial Approximation Tree from the [NMSLIB](https://github.com/nmslib/nmslib).
* BRUTEFORCENMS: Brute-force (sequential) searching from the [NMSLIB](https://github.com/nmslib/nmslib)
* ANNOY:        [Approximate Nearest Neighbors Matcher](https://github.com/spotify/annoy)
* LKOF:         Lucas Kanade Optical Flow
* LKOFT:        Lucas Kanade Optical Flow Tracker
* ALKOF:        Advanced Lucas Kanade Optical Flow
* ALKOFT:       Advanced Lucas Kanade Optical Flow Tracker

## Supported Correspondence Filtering Techniques <a name="support-filtering"></a>

After matching, we provide possibilities to filter found matches:
* Descriptor distance ratio filter (Lowe's ratio test)
* GMS: [Grid-based Motion Statistics for Fast, Ultra-robust Feature Correspondence](https://github.com/JiawangBian/GMS-Feature-Matcher)
* VFC: [Vector Field Consensus](https://github.com/jiayi-ma/VFC)
* SOF: [Statistical Optical Flow](https://link.springer.com/chapter/10.1007/978-3-319-46478-7_7)

## Supported Pose Estimation Algorithms <a name="support-pose"></a>

This library supports multiple algorithms and combinations thereof to estimate relative poses between cameras.
We included several ***random sample consensus algorithms***:
* RANSAC
* [USAC](https://ieeexplore.ieee.org/document/6365642) (adapted to estimate PROSAC beta and SPRT delta)
* [ARRSAC](https://github.com/rust-cv/arrsac)
* [MLESAC](http://www.robots.ox.ac.uk/~vgg/publications/papers/torr00.pdf)
* [NG-RANSAC](https://github.com/vislearn/ngransac) (not included in this repository but integrated in the [testing-version of this library](https://github.com/josefmaierfl/autocalib_test_package/tree/ngransac))

USAC additionally supports the ***detection and correction of degenerate cases*** (translation only, rotation only, no motion) using [QDEGSAC](https://people.inf.ethz.ch/pomarc/pubs/QDEGSAC.pdf) or a USAC-internal solution.

The following algorithms for ***pose estimation*** can be used within RANSAC variants:
* 5pt solvers (some of them from [OpenGV](http://laurentkneip.github.io/opengv/))
    * [Nister](http://www.ee.oulu.fi/research/imag/courses/Sturm/nister04.pdf)
    * [Stewenius](http://www.robots.ox.ac.uk/~vgg/publications/papers/stewenius05a.pdf)
    * [Kneip](http://laurentkneip.github.io/opengv/)
* [8pt algorithm](http://www.cs.cmu.edu/afs/andrew/scs/cs/15-463/f07/proj_final/www/amichals/fundamental.pdf)
* Homography alignment

For each of the afore mentioned algorithms different ***cost functions*** can be chosen:
* Squared norm
* Torr weights ([Torr dissertation](http://www.robots.ox.ac.uk/~phst/Papers/SPIE93/m.ps.gz), Eqn. 2.25)
* [Pseudo-Huber](https://en.wikipedia.org/wiki/Huber_loss)

Robustly estimated minimal sample models (i.e. Essential matrix or rotation matrix and translation vector) can be subsequently ***refined*** utilizing all inliers by a combination of above mentioned solvers and cost functions.

In addition, models can be refined by applying ***bundle adjustment (BA)*** on extrinsics only or on both, extrinsics and intrinsics.

We further implemented a ***linear rectification algorithm*** for general, unconstrained stereo rigs based on the publication ["A compact algorithm for rectification of stereo pairs"](https://link.springer.com/article/10.1007/s001380050120).

All above mentioned methods, algorithms, and cost functions can further be used within a ***continious high accurate relative stereo pose estimation framework*** which estimates a relative stereo pose and refines it utilizing additional stereo image pairs by concatenating the "best" correspondences over multiple stereo frames while detecting pose changes.

## Installation <a name="installation"></a>

The library was tested on Ubuntu and Windows but we provide a [Docker](https://docs.docker.com/get-docker/) file for operating system independent usage.
We provide multiple possibilities to use this software:
* Stand-alone executables to
    * Calculate image features and perform matching based on images stored on disk
    * Calculate relative poses (mono and stereo cameras) based on images and calibration (camera intrinsics) info (based on [KITTI format](https://s3.eu-central-1.amazonaws.com/avg-kitti/devkit_raw_data.zip)) stored on disk
    * Test algorithms based on GT data generated by [SemiRealSequence](https://github.com/josefmaierfl/SemiRealSequence)
* [Docker](https://docs.docker.com/get-docker/) image with afore mentioned stand-alone executables
* [ROS interface](https://github.com/josefmaierfl/matchinglib_poselib_ros)
* Library for integration into your own application

### Dependencies <a name="dependencies"></a>

#### Docker <a name="docker"></a>

If you only want to use the provided executables, [Docker](https://docs.docker.com/get-docker/) can be used.
After installing Docker, the corresponding Docker image can be built by executing `./build_docker_base.sh` in the main directory of this repository.
On Windows, the image can be built by executing `docker build -t poselib:1.0 .` in the main directory of this repository using Powershell.

#### System-wide Installation on Linux Systems <a name="system-dependencies"></a>

SemiRealSequence depends on the following libraries:
* [Eigen 3.3.7](http://eigen.tuxfamily.org/index.php?title=Main_Page)
* [Boost](https://www.boost.org/)
* [OpenCV 4.2.0](https://opencv.org/)
* [SBA](https://github.com/balintfodor/sba)
* [CLAPACK](https://github.com/NIRALUser/CLAPACK)

For installing above libraries, the following packages should be installed:
```bash
sudo apt-get update
sudo apt-get install libboost-all-dev
sudo apt-get install build-essential cmake pkg-config
sudo apt-get install wget \
    libtbb2 \
    libtbb-dev \
    libglew-dev \
    qt5-default \
    libxkbcommon-dev \
    libflann-dev \
    libpng-dev \
    libgtk-3-dev \
    libgtkglext1 \
    libgtkglext1-dev \
    libtiff-dev \
    libtiff5-dev \
    libtiffxx5 \
    libjpeg-dev \
    libjasper1 \
    libjasper-dev \
    libavcodec-dev \
    libavformat-dev \
    libswscale-dev \
    libv4l-dev \
    libxvidcore-dev \
    libx264-dev \
    libdc1394-22-dev \
    openexr \
    libatlas-base-dev \
    gfortran
sudo apt-get install libglu1-mesa-dev mesa-common-dev mesa-utils freeglut3-dev
sudo apt-get install libomp-dev
```
All mentioned libries (OpenCV, ...) can be installed by executing `./build_thirdparty.sh` within directory `ci` of this repository.
If some of the libraries are already installed on your system, missing libraries can be installed using the corresponding script file within directory [ci](./ci).
CLAPACK and SBA can be installed by executing commands below within directory [ci](./ci):
```bash
thirdparty_dir="$(pwd)/thirdparty"
cd ${thirdparty_dir}/clapack-3.2.1/build/generic
./build.sh
cd ${thirdparty_dir}/sba-1.6/build/generic
./build.sh
```

Libraries integrated into this library (no need for installation):
* [FLANN library](https://github.com/mariusmuja/flann)
* [NMSLIB](https://github.com/nmslib/nmslib)
* [ANNOY](https://github.com/spotify/annoy)
* [nanoflann](https://github.com/jlblancoc/nanoflann)
* [GMS](https://github.com/JiawangBian/GMS-Feature-Matcher)
* [VFC](https://github.com/jiayi-ma/VFC)
* [BOLD](https://github.com/vbalnt/bold)
* [RIFF](https://press.liacs.nl/researchdownloads/riff/Descriptor_Project(mm2014).zip)
* [ARRSAC](https://github.com/rust-cv/arrsac)
* [USAC](http://www.cs.unc.edu/~rraguram/usac/)
* [OpenGV](http://laurentkneip.github.io/opengv/)

### Using Stand-Alone Executables without Docker <a name="executable"></a>

After [installing dependencies](#system-dependencies), the library and executables can be built by executing `./build_install_matchinglib_poselib.sh exe` (no system-wide installation) or by (within main repository directory)
```bash
cd matchinglib_poselib
mkdir build
cd build
cmake .. -DCMAKE_BUILD_TYPE=Release -DOPTION_BUILD_TESTS=ON
make -j "$(nproc)"
```
Executables for matching features `matchinglib-test`, pose estimation `poselib-test`, and testing `noMatch_poselib-test` are located in the build folder.

### Library <a name="library"></a>

To use the library within your own application, install all necessary [dependencies](#system-dependencies) and subsequently build and install it by calling

`./build_install_matchinglib_poselib.sh install`

or by performing the following steps:

```bash
cd matchinglib_poselib
mkdir build
cd build
cmake .. -DCMAKE_BUILD_TYPE=Release -DOPTION_BUILD_TESTS=OFF -DBUILD_SHARED_LIBS=ON
make -j "$(nproc)"
sudo make install
```

To integrate it within CMake include the following into your `CMakeLists.txt`:

```
find_package(matchinglib_poselib REQUIRED)
find_package(Eigen REQUIRED)
find_package(OpenCV 4.2.0 REQUIRED)

target_link_libraries(your_project_name
  ${OpenCV_LIBS}
  sba
  ${CLAPACK_LIBRARIES}
  matchinglib_poselib::matchinglib
  matchinglib_poselib::poselib)

target_include_directories(your_project_name
  PRIVATE
  ${DEFAULT_INCLUDE_DIRECTORIES}
  ${OpenCV_INCLUDE_DIRS}
  ${Eigen_INCLUDE_DIR}
  ${CLAPACK_INCLUDE_DIRS}
  matchinglib_poselib::matchinglib
  matchinglib_poselib::poselib)
```

## Quick Start: Using Provided Test Data <a name="quick-start"></a>

This repository includes a small test data set (images and intrinsics calibration information) which is copied into the build directory during the CMake build process.
This can be disabled by providing options `-DCOPY_TEST_MATCH_IMGS=OFF` and/or `COPY_TEST_POSE_IMGS=OFF` to CMake.

### Sparse Feature Matching <a name="quick-matching"></a>

To start extracting features and calculating matches utilizing some default parameters call `./matchinglib-test` within your build directory or, if you are using Docker, run `./run_docker_base.sh match` within the main directory of this repository.
This will show a subset of found matches for every image pair.

To change parameters and/or the directory containing images execute `./matchinglib-test -h` or `./run_docker_base.sh match -h` to show options.

### Pose Estimation <a name="quick-pose"></a>

To start extracting features, calculating matches, and estimating poses utilizing some default parameters call `./poselib-test` within your build directory or, if you are using Docker, run `./run_docker_base.sh pose` within the main directory of this repository.
This will show a subset of found matches and rectified images for every input image pair.
The accuracy of estimated poses and rectification can be checked by moving your mouse cursor on the rectified images.

To change parameters and/or the directory containing images execute `./poselib-test -h` or `./run_docker_base.sh pose -h` to show options.

## Stand-Alone Executable for Feature Matching <a name="executable-matching"></a>